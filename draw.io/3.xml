class RFAConvWithDualAttention(nn.Module):
    def __init__(self, in_channel, out_channel, kernel_size, stride=1, reduction_ratio=16):
        super().__init__()
        self.kernel_size = kernel_size
        
        # 空间注意力部分
        self.get_weight = nn.Sequential(
            nn.AvgPool2d(kernel_size=kernel_size, padding=kernel_size // 2, stride=stride),
            nn.Conv2d(in_channel, in_channel * (kernel_size ** 2), kernel_size=1, groups=in_channel, bias=False)
        )
        
        self.generate_feature = nn.Sequential(
            nn.Conv2d(in_channel, in_channel * (kernel_size ** 2), kernel_size=kernel_size, 
                     padding=kernel_size//2, stride=stride, groups=in_channel, bias=False),
            nn.BatchNorm2d(in_channel * (kernel_size ** 2)),
            nn.ReLU()
        )
        
        # 通道注意力模块 - 在空间注意力处理后应用
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channel, in_channel // reduction_ratio, kernel_size=1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_channel // reduction_ratio, in_channel, kernel_size=1, bias=False),
            nn.Sigmoid()
        )
        
        self.conv = nn.Sequential(
            nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=kernel_size),
            nn.BatchNorm2d(out_channel),
            nn.ReLU()
        )
    
    def forward(self, x):
        b, c = x.shape[0:2]
        
        # 先应用空间注意力
        weight = self.get_weight(x)
        h, w = weight.shape[2:]
        weighted = weight.view(b, c, self.kernel_size ** 2, h, w).softmax(2)
        
        feature = self.generate_feature(x).view(b, c, self.kernel_size ** 2, h, w)
        weighted_data = feature * weighted
        
        conv_data = rearrange(weighted_data, 'b c (n1 n2) h w -> b c (h n1) (w n2)', 
                             n1=self.kernel_size, n2=self.kernel_size)
        
        # 在空间整理后的数据上应用通道注意力
        spatial_features = self.conv[0](conv_data)  # 只应用卷积部分，不包括BN和ReLU
        channel_weights = self.channel_attention(spatial_features)
        channel_weighted_features = spatial_features * channel_weights
        
        # 应用剩余的BN和ReLU
        output = self.conv[1:](channel_weighted_features)
        
        return output